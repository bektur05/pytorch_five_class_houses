{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPrpfGN7FNkO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/five_class.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('.')"
      ],
      "metadata": {
        "id": "uQ4Q-tP5FPhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_gray = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "otGA2M9TFPeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(root='/content/five_class/train', transform=transform_gray)\n",
        "test_data = datasets.ImageFolder(root='/content/five_class/test', transform=transform_gray)"
      ],
      "metadata": {
        "id": "p4S0XmrzFPbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_data.classes\n",
        "classes"
      ],
      "metadata": {
        "id": "G29CGONyFPYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "test = DataLoader(test_data, batch_size=16, )"
      ],
      "metadata": {
        "id": "NLWInDQqFPT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train))\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(10):\n",
        "  plt.subplot(5, 5, i + 1)\n",
        "  img = images[i].squeeze(0)\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.title(f'Class:{classes[labels[i]]}')\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2Vf3KtpQkYAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CheckImageGray(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.first = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.second = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 16 * 16, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 5),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.first(x)\n",
        "        x = self.second(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cONbjonZFPIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "gyBciV8EFPFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CheckImageGray().to(device)"
      ],
      "metadata": {
        "id": "4jlnmjBzFPDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "wLY-TK2TFPAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(15):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for x_batch, y_batch in train:\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "    y_pred = model(x_batch)\n",
        "    loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  print(f\"Эпоха {epoch + 1}, Потерии: {round(total_loss, 2)}\")"
      ],
      "metadata": {
        "id": "DWc8p7NtFO91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        y_pred = model(x_batch)\n",
        "        predicted = torch.argmax(y_pred, dim=1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Точность модели на тестовых данных: {round(accuracy, 2)}%')"
      ],
      "metadata": {
        "id": "SLHy665PFO7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_gray.pth')"
      ],
      "metadata": {
        "id": "JTucLgwhFO4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iN_t88qNFO1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yO5yIbnjFOy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dL3YOZ6VFOwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rc8GYgpqFOti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UcxpUsCFFOqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tlGA1dnXFOoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TIGSz4D_FOlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eZ2YKmg_FOiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J6wTxg6TFOgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EyCO2AyjFOdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Ve3QqsrFOav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vv9_-4KIFOYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffa88f9c"
      },
      "source": [
        "# Task\n",
        "The user wants to understand and fix an error occurring during the evaluation of a machine learning model. The error is likely related to loading or processing images in the test dataset. The plan is to identify and exclude problematic images from the dataset, create a new dataloader with the filtered data, and then re-run the evaluation to see if the error is resolved and report the final accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88c80156"
      },
      "source": [
        "## Identify problematic images\n",
        "\n",
        "### Subtask:\n",
        "Iterate through the test dataset paths and attempt to open each image file using PIL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e792b2ad"
      },
      "source": [
        "**Reasoning**:\n",
        "The goal is to identify problematic images in the test dataset by attempting to open each image file using PIL and catching the `UnidentifiedImageError`. This involves iterating through the test dataset paths, using a try-except block to handle potential errors during image opening, and storing the paths of problematic images in a list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d7ea9d9"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "problematic_images = []\n",
        "for image_path, _ in test_data.samples:\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "    except UnidentifiedImageError:\n",
        "        problematic_images.append(image_path)\n",
        "        print(f\"Problematic image file: {image_path}\")\n",
        "\n",
        "print(f\"Total problematic images found: {len(problematic_images)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e68a667"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because `UnidentifiedImageError` was not imported from `PIL.Image`. This command will import the necessary error type and re-run the code to identify problematic images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOtqNNfjW76R"
      },
      "source": [
        "from PIL import Image, UnidentifiedImageError\n",
        "\n",
        "problematic_images = []\n",
        "for image_path, _ in test_data.samples:\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "    except UnidentifiedImageError:\n",
        "        problematic_images.append(image_path)\n",
        "        print(f\"Problematic image file: {image_path}\")\n",
        "\n",
        "print(f\"Total problematic images found: {len(problematic_images)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18190c26"
      },
      "source": [
        "## Filter dataset\n",
        "\n",
        "### Subtask:\n",
        "Create a new list of image paths and labels, excluding the problematic images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72e88a2b"
      },
      "source": [
        "**Reasoning**:\n",
        "Create filtered lists of image paths and labels by excluding problematic images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b6a4d22"
      },
      "source": [
        "filtered_image_paths = []\n",
        "filtered_labels = []\n",
        "\n",
        "for image_path, label in test_data.samples:\n",
        "    if image_path not in problematic_images:\n",
        "        filtered_image_paths.append(image_path)\n",
        "        filtered_labels.append(label)\n",
        "\n",
        "print(f\"Number of filtered images: {len(filtered_image_paths)}\")\n",
        "print(f\"Number of filtered labels: {len(filtered_labels)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e1d5cc4"
      },
      "source": [
        "## Create new dataloader\n",
        "\n",
        "### Subtask:\n",
        "Create a new test DataLoader using the filtered data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7188e21"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement a custom dataset class and create a new DataLoader using the filtered image paths and labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a91f199"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FilteredImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "filtered_test_data = FilteredImageDataset(filtered_image_paths, filtered_labels, transform_rgb)\n",
        "test_filtered = DataLoader(filtered_test_data, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f743f67"
      },
      "source": [
        "## Re-run evaluation\n",
        "\n",
        "### Subtask:\n",
        "Run the evaluation loop with the new test DataLoader.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e19e10bc"
      },
      "source": [
        "**Reasoning**:\n",
        "Run the evaluation loop using the new filtered test DataLoader to evaluate the model's performance on the clean data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ae26b7e"
      },
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_filtered:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        y_pred = model(x_batch)\n",
        "        predicted = torch.argmax(y_pred, dim=1)\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on filtered test data: {round(accuracy, 2)}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ad1efc"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Three problematic images were identified in the original test dataset that caused errors during loading.\n",
        "*   A filtered test dataset was created by excluding the identified problematic images, resulting in 497 images and labels.\n",
        "*   A new test DataLoader was successfully created using the filtered data.\n",
        "*   Evaluating the model with the filtered test data resulted in an accuracy of 50.70%.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The issue of problematic images causing errors during model evaluation was resolved by filtering the dataset.\n",
        "*   Further investigation could be done to understand why the three images were problematic (e.g., corrupted files, incorrect format) and if this issue exists in other parts of the dataset or during training.\n"
      ]
    }
  ]
}